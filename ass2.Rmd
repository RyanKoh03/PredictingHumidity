---
title: "Assignment2"
output: html_document
date: "2023-05-02"
---

# FIT3152 Assignment 2

##### Name : Ryan Koh Wai Leong

##### ID : 32245181

```{r message=FALSE, warning=FALSE}
#loading necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)
library(tree)
library(e1071)
library(ROCR)
library(pROC)
library(randomForest)
library(adabag)
library(rpart)
library(doParallel)
library(iterators)
library(parallel)
library(lattice)
```

```{r}
#generating the data
rm(list = ls())
WAUS <- read.csv("HumidPredict2023D.csv")
L <- as.data.frame(c(1:49))
set.seed(32245181) # Your Student ID is the random seed
L <- L[sample(nrow(L), 10, replace = FALSE),] # sample 10 locations
WAUS <- WAUS[(WAUS$Location %in% L),]
WAUS <- WAUS[sample(nrow(WAUS), 2000, replace = FALSE),] # sample 2000 rows

```

```{r}
#removing all NAs in the data
WAUS <- na.omit(WAUS)

#changing all categorical variables to factors
WAUS$MHT <- as.factor(WAUS$MHT)
WAUS$WindDir3pm <- as.factor(WAUS$WindDir3pm)
WAUS$WindDir9am <- as.factor(WAUS$WindDir9am)
WAUS$WindGustDir <- as.factor(WAUS$WindGustDir)
WAUS$RainToday <- as.factor(WAUS$RainToday)
WAUS$Location <- as.factor(WAUS$Location)
```

```{r}
str(WAUS)
```

```{r}
head(WAUS)
```

## Question 1

#### Proportion of days when it is more humid to days when it is less humid

```{r}
humid_prop <- WAUS %>% group_by(MHT) %>% summarise(total = n(), .groups  = 'drop')

ggplot(humid_prop, aes(x = MHT, y = total, fill = MHT)) + geom_bar(stat = 'identity', width = 0.3) + geom_text(aes(label=total), position=position_dodge(width=0.9), vjust=-0.25) + labs(title = 'Proportion of Days More Humid to Less Humid', x = 'Humidity', y = 'Total observations')  + scale_x_discrete(labels = c('Less Humid','More Humid')) + scale_fill_discrete(labels = c('Less Humid','More Humid'))
```

Referring to the bar chart above, we can see that there are 42 more less humid days than there are more humid days. The ratio of less humid to more humid days is 78:71 days.

#### Investigating Minimum and Maximum Temperature

```{r}
#getting the min and max temp column
min_max <- as.data.frame(subset(WAUS, select = c(MinTemp, MaxTemp)))

#getting the mean and standard deviation
max_temp <- min_max %>% summarise_at(vars(MaxTemp),list(mean = mean, sd = sd))
min_temp <- min_max %>% summarise_at(vars(MinTemp),list(mean = mean, sd = sd))
min_temp$name <- c('MinTemp')
max_temp$name <- c('MaxTemp')

#combining both min and max temperature
min_max <- rbind(max_temp,min_temp)

#plotting the temperature
ggplot(min_max, aes(x = name, y = mean, fill = name, color = 'red')) + geom_point(shape = 15) + geom_errorbar(aes(ymin= mean-sd, ymax=mean+sd), width=.2,position=position_dodge(.9))+ guides(fill="none")  + guides(color = 'none')
```

As seen above, the mean MaxTemp is 25.0 degrees Celsius and the mean MinTemp is 14.1 degrees Celsius. The standard deviation for MaxTemp is 7.23 degrees Celsius and the standard deviation for MinTemp is 6.88 degrees Celsius.

```{r}
#function to calculate the mean and standard deviation
mean_sd <- function(dataframe, colname){
  mean_sd <- dataframe %>% summarise_at(vars(colname),list(mean=mean,sd=sd))
  mean_sd <- signif(mean_sd,3)
  mean_sd$name <- c(colname)
  return (mean_sd)
}
```

#### Investigating the Rainfall, Evaporation and Sunshine

```{r message=FALSE, warning=FALSE}
rain_eva_sun <- as.data.frame(subset(WAUS, select = c(Rainfall,Evaporation,Sunshine)))

#getting the rainfall, evaporation and sunshine mean and std dev
rainfall <- mean_sd(rain_eva_sun,'Rainfall')
evaporation <- mean_sd(rain_eva_sun,'Evaporation')
sunshine <- mean_sd(rain_eva_sun,'Sunshine')

rain_eva_sun <- rbind(evaporation,rainfall,sunshine)


ggplot(rain_eva_sun, aes(x = name, y = mean, fill = name)) + geom_bar(stat= 'identity', width = 0.2) + geom_text(aes(label=mean), position=position_dodge(width=0.9), vjust=-0.5, hjust = -0.3)  + geom_errorbar(aes(ymin= mean, ymax=mean+sd), width=.2,position=position_dodge(.9)) +  labs(title = 'Mean and Standard Deviation of Rainfall,Evaporation and Sunshine', x = 'Variable', fill = 'Variable') + facet_wrap(~name,scales = 'free', strip.position = "left", labeller = as_labeller(c(Rainfall = "Rainfall in mm",Evaporation = "Evaporation in mm",Sunshine = 'Hours of bright Sunshine over the day') )) + ylab(NULL) + theme(strip.background = element_blank(),strip.placement = "outside")
```

Referring to the chart above,

The mean rainfall in a day is 1.87 mm with a standard deviation of 6.03.

The mean evaporation in a day is 5.47mm with a standard deviation of 3.21

The mean hours of sunshine in a day is 7.68 hours with a standard deviation of 3.74

#### Investigating the Wind Speed

```{r message=FALSE, warning=FALSE}
wind <- subset(WAUS, select = c(WindGustSpeed,WindSpeed9am,WindSpeed3pm))

wind_gust <- mean_sd(wind,'WindGustSpeed')
wind_am <- mean_sd(wind,'WindSpeed9am')
wind_pm <- mean_sd(wind,'WindSpeed3pm')

wind <- rbind(wind_gust,wind_am,wind_pm)

ggplot(wind, aes(x = name, y = mean, fill = name)) + geom_bar(stat= 'identity', width = 0.2) + geom_text(aes(label=mean), position=position_dodge(width=0.9), vjust=-0.5, hjust = -0.2)  + geom_errorbar(aes(ymin= mean-sd, ymax=mean+sd), width=.2,position=position_dodge(.9)) +  labs(title = 'Mean and Standard Deviation of Wind', x = 'Variable', fill = 'Variable') + facet_wrap(~name,scales = 'free', strip.position = "left", labeller = as_labeller(c(WindGustSpeed = "Speed (km/h)",WindSpeed3pm = "Speed (km/hr) averaged over 10 minutes prior to 3pm.",WindSpeed9am = 'Speed (km/hr) averaged over 10 minutes prior to 9am') )) + ylab(NULL) + theme(strip.background = element_blank(),strip.placement = "outside")
```

As see above,

The mean WindGustSpeed is 38.6 km/h with a standard deviation of 13.3 km/h

The mean WindSpeed3pm is 17.6km/h with a standard deviation of 17.6 km/h with a standard deviation of 8.02 km/h

The mean WindSpeed9am is 13.9km/h with a standard deviation of 7.62 km/h

#### Investigating the Atmospheric Pressure

```{r}
pressure<- subset(WAUS, select = c(Pressure9am, Pressure3pm))

pressure_am <- mean_sd(pressure,'Pressure9am')
pressure_pm <- mean_sd(pressure,'Pressure3pm')

pressure <- rbind(pressure_am,pressure_pm)

ggplot(pressure, aes(x = name, y = mean, fill = name)) + geom_bar(stat= 'identity', width = 0.2) + geom_text(aes(label=mean), position=position_dodge(width=0.9), vjust=-0.5, hjust = -0.2)  + geom_errorbar(aes(ymin= mean-sd, ymax=mean+sd), width=.2,position=position_dodge(.9)) +  labs(title = 'Mean and Standard Deviation of Presure', x = 'Variable', fill = 'Variable') + facet_wrap(~name,scales = 'free', strip.position = "left", labeller = as_labeller(c(Pressure9am = "Atmospheric pressure (hpa) reduced 
to mean sea level at 9am.",Pressure3pm = "Atmospheric pressure (hpa) reduced to mean sea level at 3pm"))) + ylab(NULL) + theme(strip.background = element_blank(),strip.placement = "outside")
```

As seen above,

The mean atmospheric pressure reduced to mean sea level at 3 pm is 1010 hpa with a standard deviation of 6.80 hpa.

The mean atmospheric pressure reduced to mean sea level at 9am is 1020 hpa with a standard deviation of 6.87 hpa.

#### Investigating the fraction of sky obscured by cloud.

```{r}
cloud <- subset(WAUS, select = c(Cloud9am, Cloud3pm))
cloud_am <- mean_sd(cloud,'Cloud9am')
cloud_pm <- mean_sd(cloud,'Cloud3pm')

cloud <- rbind(cloud_am,cloud_pm)

ggplot(cloud, aes(x = name, y = mean, fill = name)) + geom_bar(stat= 'identity', width = 0.2) + geom_text(aes(label=mean), position=position_dodge(width=0.9), vjust=-0.5, hjust = -0.2)  + geom_errorbar(aes(ymin= mean, ymax=mean+sd), width=.2,position=position_dodge(.9)) +  labs(title = 'Mean and Standard Deviation fraction of sky obscured by clouds', x = 'Variable', fill = 'Variable') + facet_wrap(~name,scales = 'free', strip.position = "left", labeller = as_labeller(c(Cloud9am = "Fraction of sky obscured by cloud at 9am (oktas)",Cloud3pm = "Fraction of sky obscured by cloud at 3pm (oktas)"))) + ylab(NULL) + theme(strip.background = element_blank(),strip.placement = "outside")
```

Referring to the chart above,

The fraction of the sky obscured by clouds at 3pm has a mean value of 4.44 oktas with a standard deviation of 2.63 oktas.

The fraction of the sky obscured by clouds at 9am has a mean value of 4.31 oktas with a standard deviation of 2.79 oktas.

#### Investigating the Temperature at different times

```{r}
temp <- subset(WAUS, select = c(Temp9am, Temp3pm))

temp_am <- mean_sd(temp,'Temp9am')
temp_pm <- mean_sd(temp,'Temp3pm')

temp <- rbind(temp_am,temp_pm)

ggplot(temp, aes(x = name, y = mean, fill = name)) + geom_bar(stat= 'identity', width = 0.2) + geom_text(aes(label=mean), position=position_dodge(width=0.9), vjust=-0.5, hjust = -0.2)  + geom_errorbar(aes(ymin= mean, ymax=mean+sd), width=.2,position=position_dodge(.9)) +  labs(title = 'Mean and Standard Deviation of Temperature at 9am/3pm', x = 'Variable', fill = 'Variable') + facet_wrap(~name,scales = 'free', strip.position = "left", labeller = as_labeller(c(Temp9am = "Temperature (degrees C) at 9am",Temp3pm = "Temperature (degrees C) at 3pm."))) + ylab(NULL) + theme(strip.background = element_blank(),strip.placement = "outside")
```

As seen above,

The mean temperature at 3 pm is 23.5 degrees C with a standard deviation of 7.03 degrees C.

The mean temperature at 9am is 18.5 degrees C with a standard deviation of 7.09 degrees C.

## Question 2

All rows that have NA entries in any of the columns should be removed. This is to ensure data is consistent.

I have decided to remove Year from my analysis. This is because if we fit the classifier with the Year variable and it is fed new data from a year that was not in the training or testing data set, the classifier would perform extremely poorly.

## Question 3

#### Dividing data into training and testing data sets.

```{r}
set.seed(32245181) #Student ID as random seed 
train.row = sample(1:nrow(WAUS), 0.7*nrow(WAUS))
WAUS.train = WAUS[train.row,]
WAUS.test = WAUS[-train.row,]
```

## Question 4

#### Fitting the training data to a decision tree

```{r}
set.seed(32245181)
#fitting to a decision tree
decision <- tree(MHT~.-Year,data = WAUS.train)
summary(decision)
```

#### Fitting the training data to a Naive Bayes model

```{r}
set.seed(32245181)
naive <- naiveBayes(MHT~.-Year,data = WAUS.train)
```

#### Fitting the training data to a Random Forest model

```{r}
set.seed(32245181)
rand_for <- randomForest(formula = MHT~.-Year, data  = WAUS.train)
```

#### Fitting the training data to a decision tree with bagging method

```{r}
set.seed(32245181)
sub <- c(sample(1:125,63),sample(126:250,63),sample(251:375,63),sample(376:500,63),sample(501:625,63))
```

```{r}
set.seed(32245181)
bag <- bagging(MHT~.-Year,data = WAUS.train[sub,],mfinal = 100)
```

#### Fitting the training data with boosting method

```{r}
set.seed(32245181)
boost <- boosting(MHT~.-Year,data = WAUS.train[sub,],mfinal = 100)
```

## Question 5

```{r}
#function to calculate the true and false positive rate
tpr_fpr <- function(predictor){
  retpred <- prediction(predictor[,2],WAUS.test$MHT)
  retperf <- performance(retpred,"tpr","fpr")
  return(retperf)
}
```

#### Testing the Decision Tree model using the testing data set

```{r}
pred_dec <- predict(decision,WAUS.test,type = 'class')
dec_mat <- confusionMatrix(WAUS.test$MHT,pred_dec)
dec_mat
```

As seen by the confusion matrix above, we can see that the Decision Tree model has an accuracy of 0.532 with a True Positive Rate of 0.600 and a False Positive Rate of 0.509

#### Testing the Naive Bayes classification model using the testing data set

```{r}
pred_naive <- predict(naive,WAUS.test)
naive_mat <- confusionMatrix(WAUS.test$MHT,pred_naive)
naive_mat
```

As seen above, we can see that the Naive Bayes classification model has an accuracy of 0.587, which is slightly higher than the pruned Decision Tree model above. This model has a True Positive Rate of 0.640 and a False Positive Rate of 0.458

#### Testing the Random Forest model using the testing data set

```{r}
pred_rand <- predict(rand_for,WAUS.test)
rand_mat <- confusionMatrix(WAUS.test$MHT,pred_rand)
rand_mat
```

Referring to the confusion matrix, we can see that the Random Forest classification model has an accuracy of 0.587 which is higher than the Naive Bayes and Decision Tree model. It has a True Positive Rate of 0.647 and a False Positive Rate of 0.460.

#### Testing the Bagging classifier using the testing data set

```{r}
pred_bag <- predict.bagging(bag,WAUS.test)

pred_bag_val <- pred_bag$class
pred_bag_val <- as.factor(pred_bag_val)

bag_mat <- confusionMatrix(WAUS.test$MHT,pred_bag_val)
bag_mat
```

As seen above, we can see that the Bagging Method classifier has an accuracy of 0.543. It has a True Positive Rate of 0.589 and a False Positive Rate of 0.500.

#### Testing the Boosting classifier using the testing data set

```{r}
pred_boost <- predict.boosting(boost,newdata = WAUS.test)

pred_boost_val <- pred_boost$class
pred_boost_val <- as.factor(pred_boost_val)

boost_mat <- confusionMatrix(WAUS.test$MHT, pred_boost_val)
boost_mat
```

Referring to the confusion matrix above, we can see that the Boosting method classifier has an accuracy of 0.561. It has a True Positive Rate of 0.609 and a False Positive Rate of 0.482.

## Question 6

#### Constructing the ROC curve and calculating the AUC for all classifiers

```{r message=FALSE, warning=FALSE}
dec.r <- predict(decision,WAUS.test,type = 'vector')

naive.r <- predict(naive,WAUS.test,type = 'raw')

rand.r <- predict(rand_for,WAUS.test,type = 'prob')
```

```{r message=FALSE, warning=FALSE}
roc(WAUS.test$MHT,naive.r[,2],plot = TRUE,legacy.axes = TRUE, percent = TRUE, xlab = 'False Positive Percentage',ylab= 'True Positive Percentage', main = "ROC and AUC for each classifier",col = 'blue',lwd = 2,print.auc = TRUE)
plot.roc(WAUS.test$MHT,rand.r[,2],percent = TRUE, col = '#4daf4a',lwd = 2,print.auc = TRUE, add = TRUE,print.auc.y = 40 )
plot.roc(WAUS.test$MHT,dec.r[,2],percent = TRUE, col = 'red', lwd =2, print.auc = TRUE, add = TRUE, print.auc.y = 30)
plot.roc(WAUS.test$MHT, pred_bag$prob[,2], percent = TRUE, col = 'purple', lwd = 2, print.auc = TRUE, add = TRUE, print.auc.y = 20)
plot.roc(WAUS.test$MHT, pred_boost$prob[,2], percent = TRUE, col = '#FFC300', lwd = 2, print.auc = TRUE, add = TRUE, print.auc.y = 10)
legend("bottomright",legend = c("Naive Bayes","Random Forest", "Decision Tree","Bagging","Boosting"), col = c("blue","#4daf4a",'red','purple','#FFC300'), lwd = 2)
```

We can see from the ROC curve above that the Random Forest classifier has the highest AUC at 63.2%. This indicates that the Random Forest Classifier is adequate at determining if tomorrow will be humid or not.The other classifiers fall below 60%. This means that it would be better to just guess than to use the classifier to predict if tomorrow will be humid or not.

## Question 7

#### Creating a table with all the performance metrics for each classifier

```{r}
names <- c('Decision Tree','Naive Bayes', 'Random Forest', 'Bagging','Boosting')

tpr <- c(dec_mat$byClass[1],naive_mat$byClass[1],rand_mat$byClass[1],bag_mat$byClass[1],boost_mat$byClass[1])
tpr <- signif(tpr,3)

fpr <- c(0.509,0.458,0.460,0.500,0.482)

acc <- c(dec_mat$overall[1],naive_mat$overall[1],rand_mat$overall[1],bag_mat$overall[1],boost_mat$overall[1])
acc <- signif(acc,3)

auc <- c(0.538,0.582,0.632,0.583,0.578)

overall <- data.frame(names,tpr,fpr,acc,auc)

names(overall) <- c("Classifier","True Positive Rate", "False Positive Rate", "Accuracy","AUC")

overall
```

When comparing the performance metrics, we can see that the Random Forest Classifier could be the one 'best' classifier as it has the highest Accuracy, AUC and True Positive Rate. It also has the second lowest False Positive Rate (difference of 0.02 with the smallest) of all the classifiers.

## Question 8

```{r}
cat("Decision Tree Important Attributes\n")
print(summary(decision))
```

Referring to the summary() function above, we can see that the variables used in the Decision Tree classifier model are Rainfall, WindDir3pm, Cloud3pm, WindGustDir, Location, WindDir9am, MinTemp and Pressure9am.

```{r}
varImpPlot(rand_for,main = "Random Forest important variables")
```

Referring to the importance plot above, we can see that the most important variables in the Random Forest Classifier are WindDir3pm, WindDir9am and WindGustDir.

```{r}
bag_res <- as.data.frame(bag$importance)
ggplot(bag_res,aes(x = rownames(bag_res), y = `bag$importance`, fill = rownames(bag_res))) + geom_bar(stat = 'identity') + labs(title = "Importance of variables in bagging method", x = "Variables", y  = "Importance") + guides(fill = 'none') + coord_flip()
```

Similar to what we saw in the Random Forest variable importance plot, we can see that WindDir3pm, WindDir9am and WindGustDir are important variables for predicting whether it will be humid tomorrow or not.

```{r}
boost_res <- as.data.frame(boost$importance)
ggplot(boost_res,aes(x = rownames(boost_res), y = `boost$importance`, fill = rownames(boost_res))) + geom_bar(stat = 'identity') + labs(title = "Importance of variables in boosting method", x = "Variables", y  = "Importance") + guides(fill = 'none') + coord_flip()
```

We begin to see a pattern as WindDir3pm, WinDir9am and WindGustDir are also important variables for predicting whether it will be humid tomorrow or not in the Boosting method classifier.

To summarize, we can see that overall WindDir3pm, WindDir9am and WindGustDir are important variables for predicting whether it will be humid tomorrow or not. Furthermore, the RainToday variable can be omitted from the data with little to no effect on performance. This is supported by the fact that this variable is not used in the Decision Tree classifier and has an importance of 0 in the Random Forest, Boosting and Bagging classifiers.

## Question 9

#### Selection of classifier and the factors involved.

I chose to use the Decision Tree Classifier from question 4.

Since simplicity is the objective of this question, I chose the Decision Tree classifier as it is the easiest for a person to classify by hand.

I chose to use WindDir3pm, WindDir9am and WindGustDir in my model. Referring to Question 8 above, we can see that these three variables are the most important variables for predicting if it will be humid tomorrow or not.

```{r}
set.seed(32245181)
decision_simple <- tree(MHT ~ WindDir3pm + WindDir9am + WindGustDir, data = WAUS.train)
simple_pred <- predict(decision_simple,WAUS.test,type = "class")
simple_mat <- confusionMatrix(WAUS.test$MHT,simple_pred)
plot(decision_simple)
text(decision_simple, pretty = 0)
```

Referring to the plot above, we can interpret the Decision Tree's terminal nodes as follows starting from the leftmost terminal node.

It is predicted to be less humid tomorrow than today (MHT = 0) when the Wind Direction at 3pm (WindDir3pm) is from the East South East, North East, North North East, South, South East, South South East, South West or West South West direction and the Strongest Gust of Wind over the day (WindGustDir) is from the East, East North East, North North East, North North West, South, South South East or South West direction and the Wind Direction at 3 pm is from the South West Direction.

It is predicted to be less humid tomorrow than today (MHT = 0) when the Wind Direction at 3pm (WindDir3pm) is from the East South East, North East, North North East, South, South East, South South East, South West or West South West direction and the Strongest Gust of Wind over the day (WindGustDir) is from the East, East North East, North North East, North North West, South, South South East or South West direction and the Wind Direction at 3 pm is not from the South West Direction.

It is predicted to be less humid tomorrow than today (MHT = 0) when the Wind Direction at 3pm (WindDir3pm) is from the East South East, North East, North North East, South, South East, South South East, South West or West South West direction and the Strongest Gust of Wind over the day (WindGustDir) is not from the East, East North East, North North East, North North West, South, South South East or South West direction.

It is predicted to be more humid tomorrow than today (MHT = 1) when the Wind Direction at 3pm (WindDir3pm) is not from the East South East, North East, North North East, South, South East, South South East, South West or West South West direction.

```{r}
simple_mat
```

Referring to the confusion matrix above, we can see that this Decision Tree classifier has a accuracy of 0.487 and a True Positive Rate of 0.531 and a False Positive Rate of 0.554.

#### ROC and AUC for this simple classifier

```{r message=FALSE, warning=FALSE}
simple.r = predict(decision_simple,WAUS.test,type = "vector")

roc(WAUS.test$MHT,simple.r[,2],plot = TRUE,legacy.axes = TRUE, percent = TRUE, xlab = 'False Positive Percentage',ylab= 'True Positive Percentage', main = "ROC and AUC for Decision Tree",col = 'blue',lwd = 2,print.auc = TRUE,print.auc.y = 30)

legend("bottomright",legend = c("Decision Tree"), col = c("blue"), lwd = 2)
```

Referring to the ROC plot above, we can see that the ROC curve for this Decision Tree has an AUC of 47.9%. This means that the model performs less than adequate.

#### Compiling data into a table

```{r}
simple_data <- c(Classifier = "Simple Decision Tree", `True Postive Rate` = 0.531, `False Positive Rate` = 0.554, Accuracy = 0.487, AUC = 0.479)

overall <- rbind(overall,simple_data)

overall
```

When comparing the simple Decision Tree classifier created in Question 9 to the rest of the classifiers made in the earlier questions, we can see that the Simple Decision Tree has the worst performance overall. It has the lowest AUC, accuracy and True Positive Rate. It has the highest False Positive Rate as well. This could be because the model is too simple and could be caused by under-fitting.\

## Question 10

To make the best tree-based classifier, I chose the Random Forest classifier because it is the best performing tree based model as seen in the earlier questions.

Before implementing any changes, let's review the performance metrics of the current Random Forest model

```{r}
print(filter(overall, Classifier == "Random Forest"))
```

Now let's improve our Random Forest model

```{r}
set.seed(32245181)
new_rand <- randomForest(MHT~.-Year-RainToday, data = WAUS.train, ntree = 100)

new_pred <- predict(new_rand,WAUS.test)

newr_mat <- confusionMatrix(WAUS.test$MHT,new_pred)

newr_mat
```

#### Plotting the ROC and calculating the AUC for our improved Random Forest classifier.

```{r message=FALSE, warning=FALSE}
newrand.r = predict(new_rand,WAUS.test,type = "prob")

roc(WAUS.test$MHT,newrand.r[,2],plot = TRUE,legacy.axes = TRUE, percent = TRUE, xlab = 'False Positive Percentage',ylab= 'True Positive Percentage', main = "ROC and AUC for Improved Random Forest",col = 'darkgreen',lwd = 2,print.auc = TRUE,print.auc.y = 30)

legend("bottomright",legend = c("Improved Random Forest"), col = c("darkgreen"), lwd = 2)
```

Now let's compare this improved Random Forest classifier to the earlier classifiers.

```{r}
new_rand_data <- c(Classifier = "Improved Random Forest", `True Postive Rate` = 0.679, `False Positive Rate` = 0.446, Accuracy = 0.606, AUC = 0.633)
overall <- rbind(overall,new_rand_data)
overall
```

Referring to the table above, we can see that the improved Random Forest Classifier has the best performance metrics overall. It has the highest True Positive Rate, Accuracy and AUC. It also has the lowest False Positive Rate.

Since we discovered that the RainToday variable can be removed due to lack of significance, it was not included in the improved Random Forest classifier. I also discovered that the RainToday variable significantly decreases accuracy if it is included in the formula for this model.

To create the improved Random Forest classifier, the number of trees produced was reduced from 500 to 100. I discovered that since increasing number of trees will decrease variance which might lead to under-fitting. Therefore, I used less trees than the earlier Random Forest model to prevent under-fitting.

## Question 11

```{r message=FALSE, warning=FALSE}
library(neuralnet)
library(car)
```

```{r}
# make training and test sets
set.seed(32245181)
sub <- sample(2, nrow(WAUS), replace = TRUE, prob=c(0.8, 0.2))

WAUS$WindDir3pm <- as.numeric(WAUS$WindDir3pm)
WAUS$WindDir9am <- as.numeric(WAUS$WindDir9am)
WAUS$WindGustDir <- as.numeric(WAUS$WindGustDir)
WAUS$Location <- as.numeric(WAUS$Location)
```

Before fitting the data to an ANN, there are several things that need to be done. Firstly, we split the data set to a training and testing data set. I split the data so that 80% is used for training and 20% is used for testing.

Secondly, the columns which contain non numerical values need to be converted to a numerical format. This is done by using as.numeric() on each non numeric column. Before converting to numerical, I converted the columns to the format type first (see earlier in the report : Question 1).

```{r}
# set the seed to replicate the results
set.seed(32245181)
WAUS.train <- WAUS[sub == 1,]
WAUS.test <- WAUS[!sub ==1,]
WAUS.nn <- neuralnet(MHT ~ WindDir3pm + WindDir9am + WindGustDir + Location, WAUS.train, hidden = c(2,1))

plot(WAUS.nn)
```

Based on my findings earlier in the earlier questions, I used the 4 variables that were found to be the most important predictors for predicting whether it will be humid tomorrow or not.

```{r}
set.seed(32245181)

#make prediction
WAUS.pred <- compute(WAUS.nn, WAUS.test[,-ncol(WAUS.test)])

WAUS.pred <- as.data.frame(round(WAUS.pred$net.result,0))


#plotting the confusion matrix
table(observed = WAUS.test$MHT,predicted = WAUS.pred$V1)
```

Referring to the confusion matrix above, we can see that the Artificial Network performs adequately to predict whether it will be humid tomorrow or not. It has an accuracy of 0.556 and a True Positive Rate of 0.565 and a False Positive Rate of 0.563.

#### Plotting the ROC and calculating AUC for this ANN

```{r message=FALSE, warning=FALSE}
#store confidence results from the ANN
WAUS.pred <- compute(WAUS.nn, WAUS.test[,-ncol(WAUS.test)])
WAUS.result <- WAUS.pred$net.result
WAUS.result <- WAUS.result[,1]

#detach neuralnet package, interferes with prediction() in ROCR
detach(package:neuralnet,unload = T)
```

```{r}
library(ROCR)

#plot the ROC curve and calculate AUC
roc(WAUS.test$MHT,WAUS.result,plot = TRUE,legacy.axes = TRUE, percent = TRUE, xlab = 'False Positive Percentage',ylab= 'True Positive Percentage', main = "ROC and AUC for ANN",col = 'darkgreen',lwd = 2,print.auc = TRUE,print.auc.y = 30)

legend("bottomright",legend = c("ANN"), col = c("darkgreen"), lwd = 2)
```

Now let's add the performance metrics into the overall table to compare with the earlier classifiers

```{r}
#add performance metrics to the overall
new_ANN_data <- c(Classifier = "ANN", `True Postive Rate` = 0.565, `False Positive Rate` = 0.563, Accuracy = 0.556, AUC = 0.500)

overall <- rbind(overall, new_ANN_data)

overall
```

Referring to the table above, we can see that the ANN does not perform as well as the other classifiers. Overall, the ANN has the second lowest accuracy, AUC and True Positive Rate. It also has the highest false positive rate.

The reason the Artificial Neural Network may not be a good classifier for predicting if tomorrow will be humid or not is because it does not understand the data that is fitted to it. For example, we can change the wind direction to numerical format where North = 1 and South = 2. The ANN does not understand that North and South are complete opposites to one another and just thinks they are both just categories.

## Question 12

I chose to use the "ipred" package to implement a new classifier.

The "ipred" package is a Bagging method classifier.

Link : <https://cran.r-project.org/web/packages/ipred/ipred.pdf>

This classifier works similar to adabag but has an extra parameter to combine Stabilised Linear Discriminant Analysis with Bagging.

This package performs "double bagging" where it performs the normal bagging algorithm and combines it with the Linear Discriminant Analysis which finds a linear combination of features to classify the data.

```{r message=FALSE, warning=FALSE}
library(ipred)

#generating the data
WAUS <- read.csv("HumidPredict2023D.csv")
L <- as.data.frame(c(1:49))
set.seed(32245181) # Your Student ID is the random seed
L <- L[sample(nrow(L), 10, replace = FALSE),] # sample 10 locations
WAUS <- WAUS[(WAUS$Location %in% L),]
WAUS <- WAUS[sample(nrow(WAUS), 2000, replace = FALSE),] # sample 2000 rows

#removing all NAs in the data
WAUS <- na.omit(WAUS)

#changing all categorical variables to factors
WAUS$MHT <- as.factor(WAUS$MHT)
WAUS$WindDir3pm <- as.factor(WAUS$WindDir3pm)
WAUS$WindDir9am <- as.factor(WAUS$WindDir9am)
WAUS$WindGustDir <- as.factor(WAUS$WindGustDir)
WAUS$RainToday <- as.factor(WAUS$RainToday)
WAUS$Location <- as.factor(WAUS$Location)

set.seed(32245181) #Student ID as random seed 
train.row = sample(1:nrow(WAUS), 0.7*nrow(WAUS))
WAUS.train = WAUS[train.row,]
WAUS.test = WAUS[-train.row,]
```

#### Fitting the training data to the Bagging classifier with SLDA (Stabilized Linear Discriminant Learning)

```{r}
set.seed(32245181)

comb.lda <- list(list(model=slda, predict=function(obj, newdata)
                                 predict(obj, newdata)$x))

bag.new <- bagging(formula = MHT ~ . - Year - RainToday,data = WAUS.train, nbag = 300, control = rpart.control(minsplit = 3, cp = 0.002), comb = comb.lda)

```

#### Performing predictions

```{r}
bag.r <- predict(bag.new, newdata=WAUS.test)

table(observed = WAUS.test$MHT, predicted = bag.r)
```

Referring to the confusion matrix above, we can see that the accuracy for this Bagging classifier is 0.610 with a True Positive Rate of 0.632 and a False Positive Rate of 0.421.

#### Plotting the ROC and calculating the AUC for this Bagging classifier.

```{r}
bag.r <- predict(bag.new, newdata=WAUS.test, type = 'prob')

roc(WAUS.test$MHT,bag.r[,2],plot = TRUE,legacy.axes = TRUE, percent = TRUE, xlab = 'False Positive Percentage',ylab= 'True Positive Percentage', main = "ROC and AUC for ipred Bagging",col = 'darkgreen',lwd = 2,print.auc = TRUE,print.auc.y = 30)

legend("bottomright",legend = c("Ipred Bagging Classifier"), col = c("darkgreen"), lwd = 2)
```

Lastly, let's compare the performance metrics for this classifier with the earlier classifiers

```{r}
#add performance metrics to the overall
new_bag_data <- c(Classifier = "Bagging - new", `True Postive Rate` = 0.632, `False Positive Rate` = 0.421, Accuracy = 0.610, AUC = 0.619)

overall <- rbind(overall, new_bag_data)

overall
```

Referring to the table above, we can see that the new Bagging classifier does not outperform the improved Random Forest classifier. The improved Random Forest classifier has a higher accuracy and AUC. However, it does perform better than the earlier Bagging classifier which used the "adabag" package.
